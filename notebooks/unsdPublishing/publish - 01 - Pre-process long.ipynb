{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing script\n",
    "This script pulls SDG data from API and transforms it into csv files.\n",
    "The steps are:\n",
    "- Pull data from [API](https://unstats.un.org/SDGAPI/swagger/) \n",
    "- Join with geography\n",
    "- save as \"long\" table\n",
    "- pivot into \"wide\" format and split regional and country data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import urllib3  # allows to access a URL with python\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "import collections\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import xlsxwriter\n",
    "\n",
    "# https://volderette.de/jupyter-notebook-tip-multiple-outputs/\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\L.GonzalezMorales\\Documents\\GitHub\\FIS4SDGs\\notebooks\\unsdPublishing\n",
      "data inputs dir: ../../\n"
     ]
    }
   ],
   "source": [
    "release = '2019.Q3.G.01' # Make sure to have the correct release here\n",
    "\n",
    "dir_path = os.path.dirname(os.path.realpath('__file__'))\n",
    "print(dir_path)\n",
    "\n",
    "wd_dir = r'../../'\n",
    "print('data inputs dir: ' + wd_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert string to camelCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camelCase(st):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/8347048/camelcase-every-string-any-standard-library\n",
    "    \n",
    "    \"\"\"\n",
    "    output = ''.join(x for x in st.title() if x.isalnum())\n",
    "    return output[0].lower() + output[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disable insecure request warnings when using `urllib3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular expression to capture numeric values (including those in scientific notation)\n",
    "The regex is\n",
    "\n",
    "```\n",
    "-?      # an optional -\n",
    "\\d+     # a series of digits\n",
    "(?:     # start non capturing group\n",
    "  \\.    # a dot\n",
    "  \\d+   # a series of digits\n",
    ")?      \n",
    "(?:     # start non capturing group\n",
    "  e     # \"e\"\n",
    "  -?    # an optional -\n",
    "  \\d+   # digits\n",
    ")?\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_part(v):\n",
    "    numeric_part_f = re.compile(r'-?\\d+(?:\\.\\d+)?(?:e-?\\d+)?')\n",
    "    x = numeric_part_f.findall(v)\n",
    "    if len(x) > 0:\n",
    "        return float(x[0])\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute a hash of a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_hash(d):\n",
    "    out = hashlib.md5()\n",
    "    for key, value in d.items():\n",
    "        out.update(key.encode('utf-8'))\n",
    "        out.update(value.encode('utf-8'))\n",
    "    return out.hexdigest()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get unique dictionaries in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_dicts(dictionary_list):\n",
    "\n",
    "    uniques_map = {}\n",
    "\n",
    "    for d in dictionary_list:\n",
    "        uniques_map[dict_hash(d)] = d\n",
    "\n",
    "    return list(uniques_map.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract subset of key-value pairs from Python dictionary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subdict_list(dict_list, keys_list, exclude = False):\n",
    "    sub_d_list = []\n",
    "    if exclude:\n",
    "        for d in dict_list:\n",
    "            sub_d= {k: d[k] for k in d.keys() if k not in keys_list}\n",
    "            sub_d_list.append(sub_d)\n",
    "    else:\n",
    "        for d in dict_list:\n",
    "            sub_d= {k: d[k] for k in keys_list}\n",
    "            sub_d_list.append(sub_d)\n",
    "    \n",
    "    return sub_d_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a dict from a list based on something inside the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dict(dict_list, k, v):\n",
    "    selected = []\n",
    "    for d in dict_list:\n",
    "        if d[k] == v:\n",
    "            selected.append(d)\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of countries to be plotted on a map (with XY coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countryListXY(file):\n",
    "    \n",
    "    countryListXY = []\n",
    "    \n",
    "    with open(file, newline = '', encoding='latin-1') as countryList:                                                                                          \n",
    "        countryList = csv.DictReader(countryList, delimiter='\\t')\n",
    "        for row in countryList:\n",
    "            countryListXY.append(dict(row))\n",
    "            \n",
    "    countryListXY = pd.DataFrame(countryListXY).astype({'M49':'str'})\n",
    "    \n",
    "    return(countryListXY)\n",
    "\n",
    "    #print(countryListXY[1])\n",
    "    #for c in countryListXY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Profile</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>M49</th>\n",
       "      <th>UN_Member</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>areaName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>66.02688198</td>\n",
       "      <td>33.83160199</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ALB</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>20.06660928</td>\n",
       "      <td>41.13897007</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ATA</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>21.47585697</td>\n",
       "      <td>-80.40897662</td>\n",
       "      <td>Antarctica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>DZA</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.678164227</td>\n",
       "      <td>28.15940032</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ASM</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-170.7187269</td>\n",
       "      <td>-14.30587306</td>\n",
       "      <td>American Samoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>AND</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1.576257417</td>\n",
       "      <td>42.54548611</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>AGO</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>17.57817062</td>\n",
       "      <td>-12.33724746</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>ATG</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>-61.7999755</td>\n",
       "      <td>17.07761471</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>AZE</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>50.01064725</td>\n",
       "      <td>40.39229544</td>\n",
       "      <td>Azerbaijan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>ARG</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>-65.14563274</td>\n",
       "      <td>-35.19446255</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country_Profile ISO3 M49 UN_Member             X             Y  \\\n",
       "0               1  AFG   4         1   66.02688198   33.83160199   \n",
       "1               1  ALB   8         1   20.06660928   41.13897007   \n",
       "2               1  ATA  10         0   21.47585697  -80.40897662   \n",
       "3               1  DZA  12         1   2.678164227   28.15940032   \n",
       "4               1  ASM  16         0  -170.7187269  -14.30587306   \n",
       "5               1  AND  20         1   1.576257417   42.54548611   \n",
       "6               1  AGO  24         1   17.57817062  -12.33724746   \n",
       "7               1  ATG  28         1   -61.7999755   17.07761471   \n",
       "8               1  AZE  31         1   50.01064725   40.39229544   \n",
       "9               1  ARG  32         1  -65.14563274  -35.19446255   \n",
       "\n",
       "              areaName  \n",
       "0          Afghanistan  \n",
       "1              Albania  \n",
       "2           Antarctica  \n",
       "3              Algeria  \n",
       "4       American Samoa  \n",
       "5              Andorra  \n",
       "6               Angola  \n",
       "7  Antigua and Barbuda  \n",
       "8           Azerbaijan  \n",
       "9            Argentina  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countryListXY(wd_dir + 'globalResources/refAreas.txt').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the endpoint of the SDG API that provides the list of hierarchical groupings of geographic Areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geoAreaTree():\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', \"https://unstats.un.org/SDGAPI/v1/sdg/GeoArea/Tree\")\n",
    "    responseData = json.loads(response.data.decode('UTF-8'))\n",
    "    \n",
    "    return responseData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The geoAreaTree object has various \"trees\" in it.  We usually use the \"World\" tree; however, some economic and geographic groupings are only in other trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "root=World\n",
      "root=Least Developed Countries (LDC)\n",
      "root=Land Locked Developing Countries (LLDC)\n",
      "root=Small Island Developing States (SIDS)\n",
      "root=Developed Regions\n",
      "root=Developing Regions\n",
      "root=Custom groupings of data providers\n"
     ]
    }
   ],
   "source": [
    "print(len(geoAreaTree()))\n",
    "for t in geoAreaTree():\n",
    "    print('root='+t['geoAreaName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traverse a hierarchical tree of geographic areas and convert it to a parent-child hierarchy table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(tree):\n",
    "    \n",
    "    global hierarchy\n",
    "    \n",
    "    hierarchy = []\n",
    "    traverse.level = 1\n",
    "    traverse(tree)\n",
    "    \n",
    "    return pd.DataFrame(hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(tree, parentCode=None, parentName=None):\n",
    "    \n",
    "    # print(' ' * traverse.level + 'Level: ' + str(traverse.level) + ', ' + tree['type'] + ', ' + str(tree['geoAreaCode']) + '-' + tree['geoAreaName'] )\n",
    "    \n",
    "    d = {}\n",
    "    \n",
    "    d['level'] = traverse.level\n",
    "    d['type'] = tree['type']\n",
    "    d['parentCode'] = parentCode\n",
    "    d['parentName'] = parentName\n",
    "    d['geoAreaCode'] = str(tree['geoAreaCode'])\n",
    "    d['geoAreaName'] = tree['geoAreaName']\n",
    "    \n",
    "    hierarchy.append(d)\n",
    "        \n",
    "    if tree['children']:\n",
    "        for child in tree['children']:\n",
    "            traverse.level += 1\n",
    "            traverse(child, str(tree['geoAreaCode']), tree['geoAreaName'])\n",
    "            traverse.level -= 1\n",
    "    \n",
    "    return pd.DataFrame(hierarchy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `geoAreas` holds the flattened list of geographic areas under 'World':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoAreaCode</th>\n",
       "      <th>geoAreaName</th>\n",
       "      <th>level</th>\n",
       "      <th>parentCode</th>\n",
       "      <th>parentName</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Africa</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geoAreaCode      geoAreaName  level parentCode       parentName     type\n",
       "0           1            World      1       None             None   Region\n",
       "1          10       Antarctica      2          1            World  Country\n",
       "2           2           Africa      2          1            World   Region\n",
       "3          15  Northern Africa      3          2           Africa   Region\n",
       "4          12          Algeria      4         15  Northern Africa  Country"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoAreaCode</th>\n",
       "      <th>geoAreaName</th>\n",
       "      <th>level</th>\n",
       "      <th>parentCode</th>\n",
       "      <th>parentName</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>543</td>\n",
       "      <td>Oceania (exc. Australia and New Zealand)</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>62</td>\n",
       "      <td>Central and Southern Asia</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>513</td>\n",
       "      <td>Europe and Northern America</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>747</td>\n",
       "      <td>Northern Africa and Western Asia</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>753</td>\n",
       "      <td>Eastern and South-Eastern Asia</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    geoAreaCode                               geoAreaName  level parentCode  \\\n",
       "291         543  Oceania (exc. Australia and New Zealand)      3          9   \n",
       "292          62                 Central and Southern Asia      2          1   \n",
       "293         513               Europe and Northern America      2          1   \n",
       "294         747          Northern Africa and Western Asia      2          1   \n",
       "295         753            Eastern and South-Eastern Asia      2          1   \n",
       "\n",
       "    parentName    type  \n",
       "291    Oceania  Region  \n",
       "292      World  Region  \n",
       "293      World  Region  \n",
       "294      World  Region  \n",
       "295      World  Region  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoAreas = flatten(geoAreaTree()[0])\n",
    "geoAreas.head()\n",
    "print('...')\n",
    "geoAreas.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temporary Fix for missing regions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoAreaCode</th>\n",
       "      <th>geoAreaName</th>\n",
       "      <th>level</th>\n",
       "      <th>parentCode</th>\n",
       "      <th>parentName</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>876</td>\n",
       "      <td>Wallis and Futuna Islands</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>543</td>\n",
       "      <td>Oceania (exc. Australia and New Zealand)</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>62</td>\n",
       "      <td>Central and Southern Asia</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>513</td>\n",
       "      <td>Europe and Northern America</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>747</td>\n",
       "      <td>Northern Africa and Western Asia</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>753</td>\n",
       "      <td>Eastern and South-Eastern Asia</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>910</td>\n",
       "      <td>High income economies (WB)</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>911</td>\n",
       "      <td>Low income economies (WB)</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>912</td>\n",
       "      <td>Lower middle economies (WB)</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>913</td>\n",
       "      <td>Low and middle income economies (WB)</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>914</td>\n",
       "      <td>Upper middle economies (WB)</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>135</td>\n",
       "      <td>Caucasus and Central Asia</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>127</td>\n",
       "      <td>Southern Asia (excluding India)</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>199</td>\n",
       "      <td>Least Developed Countries (LDC)</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>485</td>\n",
       "      <td>Western Asia (exc. Armenia, Azerbaijan, Cyprus...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>514</td>\n",
       "      <td>Developed Regions</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>515</td>\n",
       "      <td>Developing Regions</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>518</td>\n",
       "      <td>Eastern Asia (excluding Japan)</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>738</td>\n",
       "      <td>Sub-Saharan Africa (inc. Sudan)</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>746</td>\n",
       "      <td>Northern Africa (exc. Sudan)</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    geoAreaCode                                        geoAreaName  level  \\\n",
       "290         876                          Wallis and Futuna Islands      4   \n",
       "291         543           Oceania (exc. Australia and New Zealand)      3   \n",
       "292          62                          Central and Southern Asia      2   \n",
       "293         513                        Europe and Northern America      2   \n",
       "294         747                   Northern Africa and Western Asia      2   \n",
       "295         753                     Eastern and South-Eastern Asia      2   \n",
       "296         910                         High income economies (WB)      1   \n",
       "297         911                          Low income economies (WB)      1   \n",
       "298         912                        Lower middle economies (WB)      1   \n",
       "299         913               Low and middle income economies (WB)      1   \n",
       "300         914                        Upper middle economies (WB)      1   \n",
       "301         135                          Caucasus and Central Asia      1   \n",
       "302         127                    Southern Asia (excluding India)      1   \n",
       "303         199                    Least Developed Countries (LDC)      1   \n",
       "304         485  Western Asia (exc. Armenia, Azerbaijan, Cyprus...      1   \n",
       "305         514                                  Developed Regions      1   \n",
       "306         515                                 Developing Regions      1   \n",
       "307         518                     Eastern Asia (excluding Japan)      1   \n",
       "308         738                    Sub-Saharan Africa (inc. Sudan)      1   \n",
       "309         746                       Northern Africa (exc. Sudan)      1   \n",
       "\n",
       "    parentCode parentName     type  \n",
       "290         61  Polynesia  Country  \n",
       "291          9    Oceania   Region  \n",
       "292          1      World   Region  \n",
       "293          1      World   Region  \n",
       "294          1      World   Region  \n",
       "295          1      World   Region  \n",
       "296       None       None    Group  \n",
       "297       None       None    Group  \n",
       "298       None       None    Group  \n",
       "299       None       None    Group  \n",
       "300       None       None    Group  \n",
       "301       None       None    Group  \n",
       "302       None       None    Group  \n",
       "303       None       None    Group  \n",
       "304       None       None    Group  \n",
       "305       None       None    Group  \n",
       "306       None       None    Group  \n",
       "307       None       None    Group  \n",
       "308       None       None    Group  \n",
       "309       None       None    Group  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if('910' not in geoAreas['geoAreaCode']):\n",
    "    d_910 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '910',\n",
    "              'geoAreaName' : 'High income economies (WB)'\n",
    "             }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_910.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('911' not in geoAreas['geoAreaCode']):\n",
    "    d_911 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '911',\n",
    "              'geoAreaName' : 'Low income economies (WB)'\n",
    "             }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_911.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "    \n",
    "if('912' not in geoAreas['geoAreaCode']):\n",
    "    d_912 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '912',\n",
    "              'geoAreaName' : 'Lower middle economies (WB)'\n",
    "             }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_912.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "if('913' not in geoAreas['geoAreaCode']):\n",
    "    d_913 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '913',\n",
    "              'geoAreaName' : 'Low and middle income economies (WB)'\n",
    "             }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_913.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "if('914' not in geoAreas['geoAreaCode']):\n",
    "    d_914 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '914',\n",
    "              'geoAreaName' : 'Upper middle economies (WB)'\n",
    "             }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_914.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "if('135' not in geoAreas['geoAreaCode']):\n",
    "    d_135 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '135',\n",
    "              'geoAreaName' : 'Caucasus and Central Asia'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_135.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('127' not in geoAreas['geoAreaCode']):\n",
    "    d_127 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '127',\n",
    "              'geoAreaName' : 'Southern Asia (excluding India)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_127.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "if('199' not in geoAreas['geoAreaCode']):\n",
    "    d_199 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '199',\n",
    "              'geoAreaName' : 'Least Developed Countries (LDC)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_199.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "if('485' not in geoAreas['geoAreaCode']):\n",
    "    d_485 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '485',\n",
    "              'geoAreaName' : 'Western Asia (exc. Armenia, Azerbaijan, Cyprus, Israel and Georgia)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_485.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('514' not in geoAreas['geoAreaCode']):\n",
    "    d_514 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '514',\n",
    "              'geoAreaName' : 'Developed Regions'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_514.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('515' not in geoAreas['geoAreaCode']):\n",
    "    d_515 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '515',\n",
    "              'geoAreaName' : 'Developing Regions'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_515.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('518' not in geoAreas['geoAreaCode']):\n",
    "    d_518 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '518',\n",
    "              'geoAreaName' : 'Eastern Asia (excluding Japan)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_518.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "\n",
    "if('738' not in geoAreas['geoAreaCode']):\n",
    "    d_738 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '738',\n",
    "              'geoAreaName' : 'Sub-Saharan Africa (inc. Sudan)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_738.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "                 \n",
    "if('746' not in geoAreas['geoAreaCode']):\n",
    "    d_746 = {'level' : 1,\n",
    "              'type' : 'Group',\n",
    "              'parentCode' : None,\n",
    "              'parentName' : None,\n",
    "              'geoAreaCode' : '746',\n",
    "              'geoAreaName' : 'Northern Africa (exc. Sudan)'\n",
    "            }\n",
    "    x = pd.DataFrame({k: [v] for k, v in d_746.items()})\n",
    "    geoAreas = geoAreas.append(x, sort = True)\n",
    "\n",
    "#==================================\n",
    "\n",
    "geoAreas = geoAreas.reset_index(drop=True)\n",
    "\n",
    "geoAreas.tail(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge coordinates and list of geographic areas in SDG database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geoAreaCode': '1',\n",
       " 'geoAreaName': 'World',\n",
       " 'level': 1,\n",
       " 'parentCode': None,\n",
       " 'parentName': None,\n",
       " 'type': 'Region'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoAreas_dict = geoAreas.to_dict('records')\n",
    "geoAreas_dict[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geoareasXY(geoareas,coordinates_file):\n",
    "    \n",
    "    xy = countryListXY(coordinates_file)\n",
    "    \n",
    "    x = pd.merge(geoareas,xy.loc[:, xy.columns != 'geoAreaName'],\n",
    "         how='outer',\n",
    "         left_on='geoAreaCode', right_on='M49')\n",
    "    x['order'] = x['geoAreaCode']\n",
    "    x['order'] = x['order'].astype(float)\n",
    "    x = x.sort_values('order')\n",
    "    del x['order']\n",
    "    del x['M49']\n",
    "    \n",
    "    x = x.reset_index(drop=True)\n",
    "    \n",
    "    x = x.to_dict('records')\n",
    "    \n",
    "    \n",
    "    x_clean = []\n",
    "    \n",
    "    for i in x:\n",
    "        i['geoAreaCode'] = i['geoAreaCode'].zfill(3)\n",
    "        if i['parentCode']:\n",
    "            i['parentCode'] = i['parentCode'].zfill(3)\n",
    "        x_clean.append({k: None if str(v) == 'nan' else v for k, v in i.items()})\n",
    "    \n",
    "    \n",
    "    \n",
    "    return(x_clean)\n",
    "\n",
    "# x.to_excel('test.xlsx', engine ='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'geoAreaCode': '001',\n",
       "  'geoAreaName': 'World',\n",
       "  'level': 1,\n",
       "  'parentCode': None,\n",
       "  'parentName': None,\n",
       "  'type': 'Region',\n",
       "  'Country_Profile': None,\n",
       "  'ISO3': None,\n",
       "  'UN_Member': None,\n",
       "  'X': None,\n",
       "  'Y': None,\n",
       "  'areaName': None},\n",
       " {'geoAreaCode': '002',\n",
       "  'geoAreaName': 'Africa',\n",
       "  'level': 2,\n",
       "  'parentCode': '001',\n",
       "  'parentName': 'World',\n",
       "  'type': 'Region',\n",
       "  'Country_Profile': None,\n",
       "  'ISO3': None,\n",
       "  'UN_Member': None,\n",
       "  'X': None,\n",
       "  'Y': None,\n",
       "  'areaName': None},\n",
       " {'geoAreaCode': '004',\n",
       "  'geoAreaName': 'Afghanistan',\n",
       "  'level': 4,\n",
       "  'parentCode': '034',\n",
       "  'parentName': 'Southern Asia',\n",
       "  'type': 'Country',\n",
       "  'Country_Profile': '1',\n",
       "  'ISO3': 'AFG',\n",
       "  'UN_Member': '1',\n",
       "  'X': '66.02688198',\n",
       "  'Y': '33.83160199',\n",
       "  'areaName': 'Afghanistan'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoareasXY(geoAreas, wd_dir + 'globalResources/refAreas.txt')[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of goals, targets, indicators and series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(wd_dir + 'globalResources/metadata.json') as json_file:  \n",
    "    metadata = json.load(json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 'SI_POV_DAY1',\n",
       " 'description': 'Proportion of population below international poverty line (%)',\n",
       " 'release': '2019.Q3.G.01',\n",
       " 'tags': ['poverty line', 'poverty', 'standard of living', 'basic needs']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[0]['targets'][0]['indicators'][0]['series'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get list of unique data series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SH_STA_BRTC',\n",
       " 'SI_COV_WKINJRY',\n",
       " 'DC_ODA_BDVL',\n",
       " 'VC_DSR_DAFF',\n",
       " 'AG_PRD_FIESSIN',\n",
       " 'SH_DYN_IMRTN',\n",
       " 'ER_MTN_GRNCOV',\n",
       " 'ER_H2O_PROCED',\n",
       " 'NV_IND_MANFPC',\n",
       " 'EN_WBE_PMPN']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = []\n",
    "for g in metadata:\n",
    "    for t in g['targets']:\n",
    "        for i in t['indicators']:\n",
    "            if 'series' in i.keys():\n",
    "                for s in i['series']:\n",
    "                    series.append(s['code'])\n",
    "series = list(set(series))\n",
    "\n",
    "series[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data for each series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify how many pages need to be requested to get all the data for a specific series from the SDG API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_request_details(seriesCode,release):\n",
    "    \n",
    "    seriesRequest = 'https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=' + seriesCode + '&releaseCode=' + release + \"&pageSize=2\"\n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', seriesRequest)\n",
    "    responseData = json.loads(response.data.decode('UTF-8'))\n",
    "    \n",
    "    pageSize = 700\n",
    "    nPages = math.floor(responseData['totalElements'] / pageSize) + 1\n",
    "    totalElements = responseData['totalElements']\n",
    "    \n",
    "    return {'series' : seriesCode,\n",
    "            'totalElements' : totalElements,\n",
    "            'nPages' : nPages, \n",
    "            'pageSize' : pageSize\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'series': 'SL_EMP_INJUR', 'totalElements': 3353, 'nPages': 5, 'pageSize': 700}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_request_details('SL_EMP_INJUR', release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the code lists of the attributes and dimensions of a series\n",
    "Describe each attribute or dimension as a simple dictionary made of a set of `code`-`description` pairs.  For the code, use the SDMX code, and not the internal codeof the database.  Keep all labels in camelCase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_code_lists(seriesCode, release):\n",
    "    \n",
    "    seriesRequest = 'https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=' + seriesCode + '&releaseCode=' + release + \"&pageSize=2\"\n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', seriesRequest)\n",
    "    responseData = json.loads(response.data.decode('UTF-8'))\n",
    "    \n",
    "    series_attributes = responseData['attributes']\n",
    "    series_dimensions = responseData['dimensions']\n",
    "    \n",
    "    new_dict = {}\n",
    "    \n",
    "    new_dict['seriesCode'] = seriesCode\n",
    "    \n",
    "    for a in series_attributes:\n",
    "        codelist_dict = {}\n",
    "        for c in a['codes']:\n",
    "            codelist_dict[c['code']] = c['description']\n",
    "        new_dict[camelCase(a['id'])] = codelist_dict\n",
    "    \n",
    "    for d in series_dimensions:\n",
    "        codelist_dict = {}\n",
    "        for c in d['codes']:\n",
    "            codelist_dict[c['code']] = c['description']\n",
    "        new_dict[camelCase(d['id'])] = codelist_dict\n",
    "        \n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seriesCode': 'SL_EMP_INJUR',\n",
       " 'nature': {'C': 'Country data',\n",
       "  'CA': 'Country adjusted data',\n",
       "  'E': 'Estimated data',\n",
       "  'G': 'Global monitoring data',\n",
       "  'M': 'Modeled data',\n",
       "  'N': 'Non-relevant',\n",
       "  'NA': 'Data nature not available'},\n",
       " 'units': {'PER_100000_EMP': 'Per 100,000 employees',\n",
       "  'PER_100000_PRSN_INSR': 'Per 100,000 persons insured',\n",
       "  'PER_100000_WKRS_EMP': 'Per 100,000 workers employed'},\n",
       " 'migratoryStatus': {'_T': 'No breakdown',\n",
       "  'MIGPER': 'Migrants',\n",
       "  'NONMIG': 'Non-migrant',\n",
       "  'EUMIG': 'EU Migrants',\n",
       "  'NONEUMIG': 'Non-EU Migrants'},\n",
       " 'reportingType': {'N': 'National', 'G': 'Global'},\n",
       " 'sex': {'FEMALE': 'Female', 'MALE': 'Male', 'BOTHSEX': 'Both sexes'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_code_lists('SL_EMP_INJUR', release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplify further by presenting all the codes and their descriptions in a single table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_code_lists2(seriesCode, release):\n",
    "    \n",
    "    seriesRequest = 'https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=' + seriesCode + '&releaseCode=' + release + \"&pageSize=2\" \n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', seriesRequest)\n",
    "    responseData = json.loads(response.data.decode('UTF-8'))\n",
    "    \n",
    "    series_attributes = responseData['attributes']\n",
    "    series_dimensions = responseData['dimensions']\n",
    "    \n",
    "    code_list = []\n",
    "    \n",
    "    for a in series_attributes:\n",
    "       \n",
    "        for c in a['codes']:\n",
    "            new_dict = {}\n",
    "            new_dict['series'] = seriesCode\n",
    "            new_dict['role'] = 'attribute'\n",
    "            new_dict['concept'] = camelCase(a['id'])\n",
    "            new_dict['code'] = c['code']\n",
    "            new_dict['sdmx'] = c['sdmx']\n",
    "            new_dict['description'] = c['description']\n",
    "            code_list.append(new_dict)\n",
    "        \n",
    "    for d in series_dimensions:\n",
    "        for c in d['codes']:\n",
    "            new_dict = {}\n",
    "            new_dict['series'] = seriesCode\n",
    "            new_dict['role'] = 'dimension'\n",
    "            new_dict['concept'] = camelCase(d['id'])\n",
    "            new_dict['code'] = c['code']\n",
    "            new_dict['sdmx'] = c['sdmx']\n",
    "            new_dict['description'] = c['description']\n",
    "            code_list.append(new_dict)\n",
    "        \n",
    "    return pd.DataFrame(code_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_code_lists3(seriesCode, release):\n",
    "    \n",
    "    seriesRequest = 'https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=' + seriesCode + '&releaseCode=' + release + \"&pageSize=2\" \n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', seriesRequest)\n",
    "    responseData = json.loads(response.data.decode('UTF-8'))\n",
    "    \n",
    "    series_attributes = responseData['attributes']\n",
    "    series_dimensions = responseData['dimensions']\n",
    "    \n",
    "    concepts = []\n",
    "    \n",
    "    for d in series_dimensions:\n",
    "\n",
    "        new_dict = {}\n",
    "        new_dict['concept'] = camelCase(d['id'])\n",
    "        new_dict['role'] = 'dimension'\n",
    "        new_dict['codes'] = []\n",
    "        for c in d['codes']:\n",
    "            new_dict2 = {}\n",
    "            new_dict2['code'] = c['code']\n",
    "            new_dict2['sdmx'] = c['sdmx']\n",
    "            new_dict2['description'] = c['description']\n",
    "            new_dict['codes'].append(new_dict2)\n",
    "        concepts.append(new_dict)\n",
    "    \n",
    "    for a in series_attributes:\n",
    "        \n",
    "        new_dict = {}\n",
    "        new_dict['concept'] = camelCase(a['id'])\n",
    "        new_dict['role'] = 'attribute'\n",
    "        new_dict['codes'] = []\n",
    "        for c in a['codes']:\n",
    "            new_dict2 = {}\n",
    "            new_dict2['code'] = c['code']\n",
    "            new_dict2['sdmx'] = c['sdmx']\n",
    "            new_dict2['description'] = c['description']\n",
    "            new_dict['codes'].append(new_dict2)\n",
    "        concepts.append(new_dict)\n",
    "        \n",
    "        \n",
    "    return concepts #pd.DataFrame(code_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>concept</th>\n",
       "      <th>description</th>\n",
       "      <th>role</th>\n",
       "      <th>sdmx</th>\n",
       "      <th>series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>nature</td>\n",
       "      <td>Country data</td>\n",
       "      <td>attribute</td>\n",
       "      <td>C</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>nature</td>\n",
       "      <td>Country adjusted data</td>\n",
       "      <td>attribute</td>\n",
       "      <td>CA</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>nature</td>\n",
       "      <td>Estimated data</td>\n",
       "      <td>attribute</td>\n",
       "      <td>E</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G</td>\n",
       "      <td>nature</td>\n",
       "      <td>Global monitoring data</td>\n",
       "      <td>attribute</td>\n",
       "      <td>G</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>nature</td>\n",
       "      <td>Modeled data</td>\n",
       "      <td>attribute</td>\n",
       "      <td>M</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N</td>\n",
       "      <td>nature</td>\n",
       "      <td>Non-relevant</td>\n",
       "      <td>attribute</td>\n",
       "      <td>N</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NA</td>\n",
       "      <td>nature</td>\n",
       "      <td>Data nature not available</td>\n",
       "      <td>attribute</td>\n",
       "      <td>_X</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PER_100000_EMP</td>\n",
       "      <td>units</td>\n",
       "      <td>Per 100,000 employees</td>\n",
       "      <td>attribute</td>\n",
       "      <td>PER_100000_EMP</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PER_100000_PRSN_INSR</td>\n",
       "      <td>units</td>\n",
       "      <td>Per 100,000 persons insured</td>\n",
       "      <td>attribute</td>\n",
       "      <td>PER_100000_PRSN_INSR</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PER_100000_WKRS_EMP</td>\n",
       "      <td>units</td>\n",
       "      <td>Per 100,000 workers employed</td>\n",
       "      <td>attribute</td>\n",
       "      <td>PER_100000_WKRS_EMP</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>_T</td>\n",
       "      <td>migratoryStatus</td>\n",
       "      <td>No breakdown</td>\n",
       "      <td>dimension</td>\n",
       "      <td>_T</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MIGPER</td>\n",
       "      <td>migratoryStatus</td>\n",
       "      <td>Migrants</td>\n",
       "      <td>dimension</td>\n",
       "      <td>MS_MIGRANT</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NONMIG</td>\n",
       "      <td>migratoryStatus</td>\n",
       "      <td>Non-migrant</td>\n",
       "      <td>dimension</td>\n",
       "      <td>MS_NOMIGRANT</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EUMIG</td>\n",
       "      <td>migratoryStatus</td>\n",
       "      <td>EU Migrants</td>\n",
       "      <td>dimension</td>\n",
       "      <td>MS_EUMIGRANT</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NONEUMIG</td>\n",
       "      <td>migratoryStatus</td>\n",
       "      <td>Non-EU Migrants</td>\n",
       "      <td>dimension</td>\n",
       "      <td>MS_NONEUMIGRANT</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>N</td>\n",
       "      <td>reportingType</td>\n",
       "      <td>National</td>\n",
       "      <td>dimension</td>\n",
       "      <td>N</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>G</td>\n",
       "      <td>reportingType</td>\n",
       "      <td>Global</td>\n",
       "      <td>dimension</td>\n",
       "      <td>G</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>sex</td>\n",
       "      <td>Female</td>\n",
       "      <td>dimension</td>\n",
       "      <td>F</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MALE</td>\n",
       "      <td>sex</td>\n",
       "      <td>Male</td>\n",
       "      <td>dimension</td>\n",
       "      <td>M</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BOTHSEX</td>\n",
       "      <td>sex</td>\n",
       "      <td>Both sexes</td>\n",
       "      <td>dimension</td>\n",
       "      <td>_T</td>\n",
       "      <td>SL_EMP_INJUR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    code          concept                   description  \\\n",
       "0                      C           nature                  Country data   \n",
       "1                     CA           nature         Country adjusted data   \n",
       "2                      E           nature                Estimated data   \n",
       "3                      G           nature        Global monitoring data   \n",
       "4                      M           nature                  Modeled data   \n",
       "5                      N           nature                  Non-relevant   \n",
       "6                     NA           nature     Data nature not available   \n",
       "7         PER_100000_EMP            units         Per 100,000 employees   \n",
       "8   PER_100000_PRSN_INSR            units   Per 100,000 persons insured   \n",
       "9    PER_100000_WKRS_EMP            units  Per 100,000 workers employed   \n",
       "10                    _T  migratoryStatus                  No breakdown   \n",
       "11                MIGPER  migratoryStatus                      Migrants   \n",
       "12                NONMIG  migratoryStatus                   Non-migrant   \n",
       "13                 EUMIG  migratoryStatus                   EU Migrants   \n",
       "14              NONEUMIG  migratoryStatus               Non-EU Migrants   \n",
       "15                     N    reportingType                      National   \n",
       "16                     G    reportingType                        Global   \n",
       "17                FEMALE              sex                        Female   \n",
       "18                  MALE              sex                          Male   \n",
       "19               BOTHSEX              sex                    Both sexes   \n",
       "\n",
       "         role                  sdmx        series  \n",
       "0   attribute                     C  SL_EMP_INJUR  \n",
       "1   attribute                    CA  SL_EMP_INJUR  \n",
       "2   attribute                     E  SL_EMP_INJUR  \n",
       "3   attribute                     G  SL_EMP_INJUR  \n",
       "4   attribute                     M  SL_EMP_INJUR  \n",
       "5   attribute                     N  SL_EMP_INJUR  \n",
       "6   attribute                    _X  SL_EMP_INJUR  \n",
       "7   attribute        PER_100000_EMP  SL_EMP_INJUR  \n",
       "8   attribute  PER_100000_PRSN_INSR  SL_EMP_INJUR  \n",
       "9   attribute   PER_100000_WKRS_EMP  SL_EMP_INJUR  \n",
       "10  dimension                    _T  SL_EMP_INJUR  \n",
       "11  dimension            MS_MIGRANT  SL_EMP_INJUR  \n",
       "12  dimension          MS_NOMIGRANT  SL_EMP_INJUR  \n",
       "13  dimension          MS_EUMIGRANT  SL_EMP_INJUR  \n",
       "14  dimension       MS_NONEUMIGRANT  SL_EMP_INJUR  \n",
       "15  dimension                     N  SL_EMP_INJUR  \n",
       "16  dimension                     G  SL_EMP_INJUR  \n",
       "17  dimension                     F  SL_EMP_INJUR  \n",
       "18  dimension                     M  SL_EMP_INJUR  \n",
       "19  dimension                    _T  SL_EMP_INJUR  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[{'concept': 'migratoryStatus',\n",
       "  'role': 'dimension',\n",
       "  'codes': [{'code': '_T', 'sdmx': '_T', 'description': 'No breakdown'},\n",
       "   {'code': 'MIGPER', 'sdmx': 'MS_MIGRANT', 'description': 'Migrants'},\n",
       "   {'code': 'NONMIG', 'sdmx': 'MS_NOMIGRANT', 'description': 'Non-migrant'},\n",
       "   {'code': 'EUMIG', 'sdmx': 'MS_EUMIGRANT', 'description': 'EU Migrants'},\n",
       "   {'code': 'NONEUMIG',\n",
       "    'sdmx': 'MS_NONEUMIGRANT',\n",
       "    'description': 'Non-EU Migrants'}]},\n",
       " {'concept': 'reportingType',\n",
       "  'role': 'dimension',\n",
       "  'codes': [{'code': 'N', 'sdmx': 'N', 'description': 'National'},\n",
       "   {'code': 'G', 'sdmx': 'G', 'description': 'Global'}]},\n",
       " {'concept': 'sex',\n",
       "  'role': 'dimension',\n",
       "  'codes': [{'code': 'FEMALE', 'sdmx': 'F', 'description': 'Female'},\n",
       "   {'code': 'MALE', 'sdmx': 'M', 'description': 'Male'},\n",
       "   {'code': 'BOTHSEX', 'sdmx': '_T', 'description': 'Both sexes'}]},\n",
       " {'concept': 'nature',\n",
       "  'role': 'attribute',\n",
       "  'codes': [{'code': 'C', 'sdmx': 'C', 'description': 'Country data'},\n",
       "   {'code': 'CA', 'sdmx': 'CA', 'description': 'Country adjusted data'},\n",
       "   {'code': 'E', 'sdmx': 'E', 'description': 'Estimated data'},\n",
       "   {'code': 'G', 'sdmx': 'G', 'description': 'Global monitoring data'},\n",
       "   {'code': 'M', 'sdmx': 'M', 'description': 'Modeled data'},\n",
       "   {'code': 'N', 'sdmx': 'N', 'description': 'Non-relevant'},\n",
       "   {'code': 'NA', 'sdmx': '_X', 'description': 'Data nature not available'}]},\n",
       " {'concept': 'units',\n",
       "  'role': 'attribute',\n",
       "  'codes': [{'code': 'PER_100000_EMP',\n",
       "    'sdmx': 'PER_100000_EMP',\n",
       "    'description': 'Per 100,000 employees'},\n",
       "   {'code': 'PER_100000_PRSN_INSR',\n",
       "    'sdmx': 'PER_100000_PRSN_INSR',\n",
       "    'description': 'Per 100,000 persons insured'},\n",
       "   {'code': 'PER_100000_WKRS_EMP',\n",
       "    'sdmx': 'PER_100000_WKRS_EMP',\n",
       "    'description': 'Per 100,000 workers employed'}]}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_code_lists2('SL_EMP_INJUR', release)\n",
    "series_code_lists3('SL_EMP_INJUR', release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build query string to collect data for a specific series from the global SDG API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_query(seriesCode, release, page, pageSize):\n",
    "    queryString =  r'https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=' + seriesCode + '&releaseCode=' + release + '&page=' + str(page) + '&pageSize=' + str(pageSize)\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', queryString)\n",
    "    responseData =  json.loads(response.data.decode('UTF-8'))\n",
    "    return(responseData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data for a specific series from the API\n",
    "*(!) Notice that a data point may appear more than once if it belongs to a \"multi-purpose indicator\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_data(seriesCode, release):\n",
    "    x = series_request_details(seriesCode,release)\n",
    "    series_data = []\n",
    "    if x['totalElements'] > 0:\n",
    "        for p in range(x['nPages']):\n",
    "            print(\"---Series \" + seriesCode + \": Processing page \" + str(p+1) + \" of \" + str(x['nPages']))\n",
    "            responseData =  series_query(seriesCode, release, p+1, x['pageSize'])\n",
    "            if len(responseData['data'])>0:\n",
    "                series_data = series_data + responseData['data'] \n",
    "    return series_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Series SL_EMP_INJUR: Processing page 1 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 2 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 3 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 4 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 5 of 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'goal': ['8'],\n",
       " 'target': ['8.8'],\n",
       " 'indicator': ['8.8.1'],\n",
       " 'series': 'SL_EMP_INJUR',\n",
       " 'seriesDescription': 'Non-fatal occupational injuries among employees, by sex and migrant status (per 100,000 employees)',\n",
       " 'seriesCount': '3353',\n",
       " 'geoAreaCode': '12',\n",
       " 'geoAreaName': 'Algeria',\n",
       " 'timePeriodStart': 2000.0,\n",
       " 'value': '1541.5',\n",
       " 'valueType': 'Float',\n",
       " 'time_detail': None,\n",
       " 'upperBound': None,\n",
       " 'lowerBound': None,\n",
       " 'basePeriod': None,\n",
       " 'source': 'ILOSTAT - ADM-IR - Insurance records',\n",
       " 'footnotes': ['Coverage of occupational injuries: Compensated injuries | Reference group coverage: Insured persons'],\n",
       " 'attributes': {'Nature': 'C', 'Units': 'PER_100000_EMP'},\n",
       " 'dimensions': {'Sex': 'BOTHSEX',\n",
       "  'Migratory status': '_T',\n",
       "  'Reporting Type': 'G'}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = series_data('SL_EMP_INJUR',release)\n",
    "if len(x) > 0:\n",
    "    x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten the dictionary, extracting individual attributes and dimensions as key-value pairs in their own right.\n",
    "Also convert the years (`timePeriod`) variable to `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geoAreaCode': '001',\n",
       " 'geoAreaName': 'World',\n",
       " 'level': 1,\n",
       " 'parentCode': None,\n",
       " 'parentName': None,\n",
       " 'type': 'Region',\n",
       " 'Country_Profile': None,\n",
       " 'ISO3': None,\n",
       " 'UN_Member': None,\n",
       " 'X': None,\n",
       " 'Y': None,\n",
       " 'areaName': None}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo = geoareasXY(geoAreas, wd_dir + 'globalResources/refAreas.txt')\n",
    "geo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_series_data(seriesCode,release):\n",
    "\n",
    "    codeLists = series_code_lists3(seriesCode,release)\n",
    "    \n",
    "    new_x = []\n",
    "    for d in series_data(seriesCode,release):\n",
    "        new_d = {}\n",
    "        for key, value in d.items():\n",
    "            if type(value) is list:\n",
    "                new_d[key] = ', '.join(value)\n",
    "            elif type(value) is dict:\n",
    "                for k, v in value.items():\n",
    "                    new_d[camelCase(k+' Code')] = v\n",
    "                    for cl in codeLists:\n",
    "                        if cl['concept'] == camelCase(k):\n",
    "                            for c in cl['codes']:\n",
    "                                if c['code'] == v:\n",
    "                                    new_d[camelCase(k+' Desc')] = c['description']\n",
    "                                    new_d[camelCase(k+' Code')] = c['sdmx']\n",
    "                                    break\n",
    "                            break\n",
    "            elif key == 'time_detail':\n",
    "                new_d[camelCase(key)] = value\n",
    "            elif key == 'timePeriodStart':\n",
    "                new_d['timePeriod'] = int(value)\n",
    "            elif key == 'series':\n",
    "                new_d['seriesCode'] = value\n",
    "            elif key == 'seriesDescription':\n",
    "                new_d['seriesDesc'] = value\n",
    "            elif key == 'geoAreaCode':\n",
    "                new_d['geoAreaCode'] = str(value).zfill(3)\n",
    "            else:\n",
    "                new_d[key] = value\n",
    "\n",
    "        new_d['value_numeric_part'] = numeric_part(new_d['value'])\n",
    "        new_d['value_is_censored'] = (new_d['valueType'] != 'Float')\n",
    "        new_d['value_detail'] = new_d['value']\n",
    "\n",
    "        del new_d['value']\n",
    "        del new_d['valueType']\n",
    "        del new_d['seriesCount']\n",
    "\n",
    "        new_x.append(new_d)\n",
    "\n",
    "    return new_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Series SL_EMP_INJUR: Processing page 1 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 2 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 3 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 4 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 5 of 5\n"
     ]
    }
   ],
   "source": [
    "x = flat_series_data('SL_EMP_INJUR',release)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'goal': '8',\n",
       " 'target': '8.8',\n",
       " 'indicator': '8.8.1',\n",
       " 'seriesCode': 'SL_EMP_INJUR',\n",
       " 'seriesDesc': 'Non-fatal occupational injuries among employees, by sex and migrant status (per 100,000 employees)',\n",
       " 'geoAreaCode': '012',\n",
       " 'geoAreaName': 'Algeria',\n",
       " 'timePeriod': 2000,\n",
       " 'timeDetail': None,\n",
       " 'upperBound': None,\n",
       " 'lowerBound': None,\n",
       " 'basePeriod': None,\n",
       " 'source': 'ILOSTAT - ADM-IR - Insurance records',\n",
       " 'footnotes': 'Coverage of occupational injuries: Compensated injuries | Reference group coverage: Insured persons',\n",
       " 'natureCode': 'C',\n",
       " 'natureDesc': 'Country data',\n",
       " 'unitsCode': 'PER_100000_EMP',\n",
       " 'unitsDesc': 'Per 100,000 employees',\n",
       " 'sexCode': '_T',\n",
       " 'sexDesc': 'Both sexes',\n",
       " 'migratoryStatusCode': '_T',\n",
       " 'migratoryStatusDesc': 'No breakdown',\n",
       " 'reportingTypeCode': 'G',\n",
       " 'reportingTypeDesc': 'Global',\n",
       " 'value_numeric_part': 1541.5,\n",
       " 'value_is_censored': False,\n",
       " 'value_detail': '1541.5'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select distinct indicator-series that are included in the dataset\n",
    "\n",
    "When there is a 'multi-purpose indicator', the same data series is part of two different goal-target-indicator specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_series = unique_dicts(subdict_list(x,['goal', 'target', 'indicator', 'seriesCode', 'seriesDesc'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each `indicator_series`, we want to build a json file that contains all the necessary information to be published as a layer. This requires to build a tree structure with the following levels:\n",
    "- Information about the goal, target, indicator, and series\n",
    "- Information about the geographic reference area\n",
    "- Data grouped by time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Series SL_EMP_INJUR: Processing page 1 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 2 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 3 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 4 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 5 of 5\n"
     ]
    }
   ],
   "source": [
    "series = 'SL_EMP_INJUR'\n",
    "\n",
    "x = flat_series_data(series,release)\n",
    "\n",
    "indicator_series =  unique_dicts(subdict_list(x,['goal', 'target', 'indicator', 'seriesCode', 'seriesDesc'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'goal': '8',\n",
       " 'target': '8.8',\n",
       " 'indicator': '8.8.1',\n",
       " 'seriesCode': 'SL_EMP_INJUR',\n",
       " 'seriesDesc': 'Non-fatal occupational injuries among employees, by sex and migrant status (per 100,000 employees)',\n",
       " 'geoAreaCode': '012',\n",
       " 'geoAreaName': 'Algeria',\n",
       " 'timePeriod': 2000,\n",
       " 'timeDetail': None,\n",
       " 'upperBound': None,\n",
       " 'lowerBound': None,\n",
       " 'basePeriod': None,\n",
       " 'source': 'ILOSTAT - ADM-IR - Insurance records',\n",
       " 'footnotes': 'Coverage of occupational injuries: Compensated injuries | Reference group coverage: Insured persons',\n",
       " 'natureCode': 'C',\n",
       " 'natureDesc': 'Country data',\n",
       " 'unitsCode': 'PER_100000_EMP',\n",
       " 'unitsDesc': 'Per 100,000 employees',\n",
       " 'sexCode': '_T',\n",
       " 'sexDesc': 'Both sexes',\n",
       " 'migratoryStatusCode': '_T',\n",
       " 'migratoryStatusDesc': 'No breakdown',\n",
       " 'reportingTypeCode': 'G',\n",
       " 'reportingTypeDesc': 'Global',\n",
       " 'value_numeric_part': 1541.5,\n",
       " 'value_is_censored': False,\n",
       " 'value_detail': '1541.5'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'geoAreaCode': '001',\n",
       " 'geoAreaName': 'World',\n",
       " 'level': 1,\n",
       " 'parentCode': None,\n",
       " 'parentName': None,\n",
       " 'type': 'Region',\n",
       " 'Country_Profile': None,\n",
       " 'ISO3': None,\n",
       " 'UN_Member': None,\n",
       " 'X': None,\n",
       " 'Y': None,\n",
       " 'areaName': None}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]\n",
    "geo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_to_json(series, release):\n",
    "    \n",
    "    x = flat_series_data(series,release)\n",
    "\n",
    "    indicator_series =  unique_dicts(subdict_list(x,['goal', 'target', 'indicator', 'seriesCode', 'seriesDesc'])\n",
    "    )\n",
    "\n",
    "    dataset = []\n",
    "    for s in indicator_series:\n",
    "        d = s.copy()\n",
    "        d['release'] = release\n",
    "        indicator = d['indicator']\n",
    "        data = select_dict(x, 'indicator', indicator)\n",
    "        d['refAreas'] = geo.copy()\n",
    "        for g in d['refAreas']:\n",
    "            g_data = subdict_list(select_dict(data, 'geoAreaCode', g['geoAreaCode']),\n",
    "                                  ['goal', 'target', 'indicator', 'seriesCode', 'seriesDesc','geoAreaCode', 'geoAreaName'], \n",
    "                                  exclude = True)\n",
    "            g['data'] = g_data\n",
    "\n",
    "        file_name = release + '\\Indicator_' + indicator + '_Series_' + d['seriesCode'] + '.json'\n",
    "\n",
    "        with open(wd_dir + r'data\\unsd\\\\' + file_name, 'w') as f:\n",
    "            json.dump(d, f, indent=4)\n",
    "        \n",
    "        print('created file ' + file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Series SL_EMP_INJUR: Processing page 1 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 2 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 3 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 4 of 5\n",
      "---Series SL_EMP_INJUR: Processing page 5 of 5\n",
      "created file 2019.Q3.G.01\\Indicator_8.8.1_Series_SL_EMP_INJUR.json\n"
     ]
    }
   ],
   "source": [
    "get_data_to_json(series, release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produce 'long' files for each indicator/series combination\n",
    "(Notice that multi-purpose indicators need to be split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = []\n",
    "for g in metadata:\n",
    "    for t in g['targets']:\n",
    "        for i in t['indicators']:\n",
    "            if 'series' in i.keys():\n",
    "                for s in i['series']:\n",
    "                    series.append(s['code'])\n",
    "series = list(set(series))\n",
    "\n",
    "series.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 391)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series no. 332\n",
      "---Series SL_TLF_UEMDIS: Processing page 1 of 2\n",
      "---Series SL_TLF_UEMDIS: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_8.5.2_Series_SL_TLF_UEMDIS.json\n",
      "series no. 333\n",
      "---Series SN_ITK_DEFC: Processing page 1 of 8\n",
      "---Series SN_ITK_DEFC: Processing page 2 of 8\n",
      "---Series SN_ITK_DEFC: Processing page 3 of 8\n",
      "---Series SN_ITK_DEFC: Processing page 4 of 8\n",
      "---Series SN_ITK_DEFC: Processing page 5 of 8\n",
      "---Series SN_ITK_DEFC: Processing page 6 of 8\n",
      "---Series SN_ITK_DEFC: Processing page 7 of 8\n",
      "---Series SN_ITK_DEFC: Processing page 8 of 8\n",
      "created file 2019.Q3.G.01\\Indicator_2.1.1_Series_SN_ITK_DEFC.json\n",
      "series no. 334\n",
      "---Series SN_ITK_DEFCN: Processing page 1 of 8\n",
      "---Series SN_ITK_DEFCN: Processing page 2 of 8\n",
      "---Series SN_ITK_DEFCN: Processing page 3 of 8\n",
      "---Series SN_ITK_DEFCN: Processing page 4 of 8\n",
      "---Series SN_ITK_DEFCN: Processing page 5 of 8\n",
      "---Series SN_ITK_DEFCN: Processing page 6 of 8\n",
      "---Series SN_ITK_DEFCN: Processing page 7 of 8\n",
      "---Series SN_ITK_DEFCN: Processing page 8 of 8\n",
      "created file 2019.Q3.G.01\\Indicator_2.1.1_Series_SN_ITK_DEFCN.json\n",
      "series no. 335\n",
      "---Series SP_ACS_BSRVH2O: Processing page 1 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 2 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 3 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 4 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 5 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 6 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 7 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 8 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 9 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 10 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 11 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 12 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 13 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 14 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 15 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 16 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 17 of 18\n",
      "---Series SP_ACS_BSRVH2O: Processing page 18 of 18\n",
      "created file 2019.Q3.G.01\\Indicator_1.4.1_Series_SP_ACS_BSRVH2O.json\n",
      "series no. 336\n",
      "---Series SP_ACS_BSRVSAN: Processing page 1 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 2 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 3 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 4 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 5 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 6 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 7 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 8 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 9 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 10 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 11 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 12 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 13 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 14 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 15 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 16 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 17 of 18\n",
      "---Series SP_ACS_BSRVSAN: Processing page 18 of 18\n",
      "created file 2019.Q3.G.01\\Indicator_1.4.1_Series_SP_ACS_BSRVSAN.json\n",
      "series no. 337\n",
      "---Series SP_DYN_ADKL: Processing page 1 of 4\n",
      "---Series SP_DYN_ADKL: Processing page 2 of 4\n",
      "---Series SP_DYN_ADKL: Processing page 3 of 4\n",
      "---Series SP_DYN_ADKL: Processing page 4 of 4\n",
      "created file 2019.Q3.G.01\\Indicator_3.7.2_Series_SP_DYN_ADKL.json\n",
      "series no. 338\n",
      "---Series SP_DYN_MRBF15: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_5.3.1_Series_SP_DYN_MRBF15.json\n",
      "series no. 339\n",
      "---Series SP_DYN_MRBF18: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_5.3.1_Series_SP_DYN_MRBF18.json\n",
      "series no. 340\n",
      "---Series TM_TAX_ATRFD: Processing page 1 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 2 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 3 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 4 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 5 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 6 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 7 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 8 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 9 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 10 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 11 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 12 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 13 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 14 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 15 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 16 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 17 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 18 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 19 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 20 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 21 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 22 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 23 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 24 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 25 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 26 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 27 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 28 of 29\n",
      "---Series TM_TAX_ATRFD: Processing page 29 of 29\n",
      "created file 2019.Q3.G.01\\Indicator_17.12.1_Series_TM_TAX_ATRFD.json\n",
      "series no. 341\n",
      "---Series TM_TAX_WWTAV: Processing page 1 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 2 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 3 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 4 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 5 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 6 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 7 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 8 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 9 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 10 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 11 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 12 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 13 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 14 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 15 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 16 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 17 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 18 of 19\n",
      "---Series TM_TAX_WWTAV: Processing page 19 of 19\n",
      "created file 2019.Q3.G.01\\Indicator_17.10.1_Series_TM_TAX_WWTAV.json\n",
      "series no. 342\n",
      "---Series TM_TRF_ZERO: Processing page 1 of 12\n",
      "---Series TM_TRF_ZERO: Processing page 2 of 12\n",
      "---Series TM_TRF_ZERO: Processing page 3 of 12\n",
      "---Series TM_TRF_ZERO: Processing page 4 of 12\n",
      "---Series TM_TRF_ZERO: Processing page 5 of 12\n",
      "---Series TM_TRF_ZERO: Processing page 6 of 12\n",
      "---Series TM_TRF_ZERO: Processing page 7 of 12\n",
      "---Series TM_TRF_ZERO: Processing page 8 of 12\n",
      "---Series TM_TRF_ZERO: Processing page 9 of 12\n",
      "---Series TM_TRF_ZERO: Processing page 10 of 12\n",
      "---Series TM_TRF_ZERO: Processing page 11 of 12\n",
      "---Series TM_TRF_ZERO: Processing page 12 of 12\n",
      "created file 2019.Q3.G.01\\Indicator_10.a.1_Series_TM_TRF_ZERO.json\n",
      "series no. 343\n",
      "---Series TX_EXP_GBMRCH: Processing page 1 of 2\n",
      "---Series TX_EXP_GBMRCH: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_17.11.1_Series_TX_EXP_GBMRCH.json\n",
      "series no. 344\n",
      "---Series TX_EXP_GBSVR: Processing page 1 of 2\n",
      "---Series TX_EXP_GBSVR: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_17.11.1_Series_TX_EXP_GBSVR.json\n",
      "series no. 345\n",
      "---Series TX_IMP_GBMRCH: Processing page 1 of 2\n",
      "---Series TX_IMP_GBMRCH: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_17.11.1_Series_TX_IMP_GBMRCH.json\n",
      "series no. 346\n",
      "---Series TX_IMP_GBSVR: Processing page 1 of 2\n",
      "---Series TX_IMP_GBSVR: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_17.11.1_Series_TX_IMP_GBSVR.json\n",
      "series no. 347\n",
      "---Series VC_DSR_AFFCT: Processing page 1 of 5\n",
      "---Series VC_DSR_AFFCT: Processing page 2 of 5\n",
      "---Series VC_DSR_AFFCT: Processing page 3 of 5\n",
      "---Series VC_DSR_AFFCT: Processing page 4 of 5\n",
      "---Series VC_DSR_AFFCT: Processing page 5 of 5\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.1_Series_VC_DSR_AFFCT.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.1_Series_VC_DSR_AFFCT.json\n",
      "created file 2019.Q3.G.01\\Indicator_13.1.1_Series_VC_DSR_AFFCT.json\n",
      "series no. 348\n",
      "---Series VC_DSR_AGLN: Processing page 1 of 3\n",
      "---Series VC_DSR_AGLN: Processing page 2 of 3\n",
      "---Series VC_DSR_AGLN: Processing page 3 of 3\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.2_Series_VC_DSR_AGLN.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_AGLN.json\n",
      "series no. 349\n",
      "---Series VC_DSR_BSDN: Processing page 1 of 2\n",
      "---Series VC_DSR_BSDN: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_BSDN.json\n",
      "series no. 350\n",
      "---Series VC_DSR_CDAN: Processing page 1 of 2\n",
      "---Series VC_DSR_CDAN: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_CDAN.json\n",
      "series no. 351\n",
      "---Series VC_DSR_CDYN: Processing page 1 of 2\n",
      "---Series VC_DSR_CDYN: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_CDYN.json\n",
      "series no. 352\n",
      "---Series VC_DSR_CHLN: Processing page 1 of 3\n",
      "---Series VC_DSR_CHLN: Processing page 2 of 3\n",
      "---Series VC_DSR_CHLN: Processing page 3 of 3\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.2_Series_VC_DSR_CHLN.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_CHLN.json\n",
      "series no. 353\n",
      "---Series VC_DSR_CILN: Processing page 1 of 3\n",
      "---Series VC_DSR_CILN: Processing page 2 of 3\n",
      "---Series VC_DSR_CILN: Processing page 3 of 3\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.2_Series_VC_DSR_CILN.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_CILN.json\n",
      "series no. 354\n",
      "---Series VC_DSR_DAFF: Processing page 1 of 5\n",
      "---Series VC_DSR_DAFF: Processing page 2 of 5\n",
      "---Series VC_DSR_DAFF: Processing page 3 of 5\n",
      "---Series VC_DSR_DAFF: Processing page 4 of 5\n",
      "---Series VC_DSR_DAFF: Processing page 5 of 5\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.1_Series_VC_DSR_DAFF.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.1_Series_VC_DSR_DAFF.json\n",
      "created file 2019.Q3.G.01\\Indicator_13.1.1_Series_VC_DSR_DAFF.json\n",
      "series no. 355\n",
      "---Series VC_DSR_DDPA: Processing page 1 of 3\n",
      "---Series VC_DSR_DDPA: Processing page 2 of 3\n",
      "---Series VC_DSR_DDPA: Processing page 3 of 3\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.2_Series_VC_DSR_DDPA.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_DDPA.json\n",
      "series no. 356\n",
      "---Series VC_DSR_EFDN: Processing page 1 of 2\n",
      "---Series VC_DSR_EFDN: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_EFDN.json\n",
      "series no. 357\n",
      "---Series VC_DSR_ESDN: Processing page 1 of 2\n",
      "---Series VC_DSR_ESDN: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_ESDN.json\n",
      "series no. 358\n",
      "---Series VC_DSR_GDPLS: Processing page 1 of 3\n",
      "---Series VC_DSR_GDPLS: Processing page 2 of 3\n",
      "---Series VC_DSR_GDPLS: Processing page 3 of 3\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.2_Series_VC_DSR_GDPLS.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_GDPLS.json\n",
      "series no. 359\n",
      "---Series VC_DSR_HFDN: Processing page 1 of 2\n",
      "---Series VC_DSR_HFDN: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_HFDN.json\n",
      "series no. 360\n",
      "---Series VC_DSR_HOLN: Processing page 1 of 3\n",
      "---Series VC_DSR_HOLN: Processing page 2 of 3\n",
      "---Series VC_DSR_HOLN: Processing page 3 of 3\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.2_Series_VC_DSR_HOLN.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_HOLN.json\n",
      "series no. 361\n",
      "---Series VC_DSR_HSDN: Processing page 1 of 2\n",
      "---Series VC_DSR_HSDN: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_HSDN.json\n",
      "series no. 362\n",
      "---Series VC_DSR_IJILN: Processing page 1 of 4\n",
      "---Series VC_DSR_IJILN: Processing page 2 of 4\n",
      "---Series VC_DSR_IJILN: Processing page 3 of 4\n",
      "---Series VC_DSR_IJILN: Processing page 4 of 4\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.1_Series_VC_DSR_IJILN.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.1_Series_VC_DSR_IJILN.json\n",
      "created file 2019.Q3.G.01\\Indicator_13.1.1_Series_VC_DSR_IJILN.json\n",
      "series no. 363\n",
      "---Series VC_DSR_LSGP: Processing page 1 of 3\n",
      "---Series VC_DSR_LSGP: Processing page 2 of 3\n",
      "---Series VC_DSR_LSGP: Processing page 3 of 3\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.2_Series_VC_DSR_LSGP.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_LSGP.json\n",
      "series no. 364\n",
      "---Series VC_DSR_MISS: Processing page 1 of 2\n",
      "---Series VC_DSR_MISS: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.1_Series_VC_DSR_MISS.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.1_Series_VC_DSR_MISS.json\n",
      "created file 2019.Q3.G.01\\Indicator_13.1.1_Series_VC_DSR_MISS.json\n",
      "series no. 365\n",
      "---Series VC_DSR_MORT: Processing page 1 of 4\n",
      "---Series VC_DSR_MORT: Processing page 2 of 4\n",
      "---Series VC_DSR_MORT: Processing page 3 of 4\n",
      "---Series VC_DSR_MORT: Processing page 4 of 4\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.1_Series_VC_DSR_MORT.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.1_Series_VC_DSR_MORT.json\n",
      "created file 2019.Q3.G.01\\Indicator_13.1.1_Series_VC_DSR_MORT.json\n",
      "series no. 366\n",
      "---Series VC_DSR_MTMN: Processing page 1 of 5\n",
      "---Series VC_DSR_MTMN: Processing page 2 of 5\n",
      "---Series VC_DSR_MTMN: Processing page 3 of 5\n",
      "---Series VC_DSR_MTMN: Processing page 4 of 5\n",
      "---Series VC_DSR_MTMN: Processing page 5 of 5\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.1_Series_VC_DSR_MTMN.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.1_Series_VC_DSR_MTMN.json\n",
      "created file 2019.Q3.G.01\\Indicator_13.1.1_Series_VC_DSR_MTMN.json\n",
      "series no. 367\n",
      "---Series VC_DSR_MTMP: Processing page 1 of 4\n",
      "---Series VC_DSR_MTMP: Processing page 2 of 4\n",
      "---Series VC_DSR_MTMP: Processing page 3 of 4\n",
      "---Series VC_DSR_MTMP: Processing page 4 of 4\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.1_Series_VC_DSR_MTMP.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.1_Series_VC_DSR_MTMP.json\n",
      "created file 2019.Q3.G.01\\Indicator_13.1.1_Series_VC_DSR_MTMP.json\n",
      "series no. 368\n",
      "---Series VC_DSR_OBDN: Processing page 1 of 2\n",
      "---Series VC_DSR_OBDN: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.2_Series_VC_DSR_OBDN.json\n",
      "series no. 369\n",
      "---Series VC_DSR_PDAN: Processing page 1 of 4\n",
      "---Series VC_DSR_PDAN: Processing page 2 of 4\n",
      "---Series VC_DSR_PDAN: Processing page 3 of 4\n",
      "---Series VC_DSR_PDAN: Processing page 4 of 4\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.1_Series_VC_DSR_PDAN.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.1_Series_VC_DSR_PDAN.json\n",
      "created file 2019.Q3.G.01\\Indicator_13.1.1_Series_VC_DSR_PDAN.json\n",
      "series no. 370\n",
      "---Series VC_DSR_PDLN: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.1_Series_VC_DSR_PDLN.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.1_Series_VC_DSR_PDLN.json\n",
      "created file 2019.Q3.G.01\\Indicator_13.1.1_Series_VC_DSR_PDLN.json\n",
      "series no. 371\n",
      "---Series VC_DSR_PDYN: Processing page 1 of 3\n",
      "---Series VC_DSR_PDYN: Processing page 2 of 3\n",
      "---Series VC_DSR_PDYN: Processing page 3 of 3\n",
      "created file 2019.Q3.G.01\\Indicator_1.5.1_Series_VC_DSR_PDYN.json\n",
      "created file 2019.Q3.G.01\\Indicator_11.5.1_Series_VC_DSR_PDYN.json\n",
      "created file 2019.Q3.G.01\\Indicator_13.1.1_Series_VC_DSR_PDYN.json\n",
      "series no. 372\n",
      "---Series VC_HTF_DETV: Processing page 1 of 2\n",
      "---Series VC_HTF_DETV: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_16.2.2_Series_VC_HTF_DETV.json\n",
      "series no. 373\n",
      "---Series VC_HTF_DETVFL: Processing page 1 of 3\n",
      "---Series VC_HTF_DETVFL: Processing page 2 of 3\n",
      "---Series VC_HTF_DETVFL: Processing page 3 of 3\n",
      "created file 2019.Q3.G.01\\Indicator_16.2.2_Series_VC_HTF_DETVFL.json\n",
      "series no. 374\n",
      "---Series VC_HTF_DETVOG: Processing page 1 of 2\n",
      "---Series VC_HTF_DETVOG: Processing page 2 of 2\n",
      "created file 2019.Q3.G.01\\Indicator_16.2.2_Series_VC_HTF_DETVOG.json\n",
      "series no. 375\n",
      "---Series VC_HTF_DETVOP: Processing page 1 of 3\n",
      "---Series VC_HTF_DETVOP: Processing page 2 of 3\n",
      "---Series VC_HTF_DETVOP: Processing page 3 of 3\n",
      "created file 2019.Q3.G.01\\Indicator_16.2.2_Series_VC_HTF_DETVOP.json\n",
      "series no. 376\n",
      "---Series VC_HTF_DETVSX: Processing page 1 of 4\n",
      "---Series VC_HTF_DETVSX: Processing page 2 of 4\n",
      "---Series VC_HTF_DETVSX: Processing page 3 of 4\n",
      "---Series VC_HTF_DETVSX: Processing page 4 of 4\n",
      "created file 2019.Q3.G.01\\Indicator_16.2.2_Series_VC_HTF_DETVSX.json\n",
      "series no. 377\n",
      "---Series VC_IHR_PSRC: Processing page 1 of 4\n",
      "---Series VC_IHR_PSRC: Processing page 2 of 4\n",
      "---Series VC_IHR_PSRC: Processing page 3 of 4\n",
      "---Series VC_IHR_PSRC: Processing page 4 of 4\n",
      "created file 2019.Q3.G.01\\Indicator_16.1.1_Series_VC_IHR_PSRC.json\n",
      "series no. 378\n",
      "---Series VC_IHR_PSRCN: Processing page 1 of 4\n",
      "---Series VC_IHR_PSRCN: Processing page 2 of 4\n",
      "---Series VC_IHR_PSRCN: Processing page 3 of 4\n",
      "---Series VC_IHR_PSRCN: Processing page 4 of 4\n",
      "created file 2019.Q3.G.01\\Indicator_16.1.1_Series_VC_IHR_PSRCN.json\n",
      "series no. 379\n",
      "---Series VC_PRR_PHYV: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_16.3.1_Series_VC_PRR_PHYV.json\n",
      "series no. 380\n",
      "---Series VC_PRR_ROBB: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_16.3.1_Series_VC_PRR_ROBB.json\n",
      "series no. 381\n",
      "---Series VC_PRR_SEXV: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_16.3.1_Series_VC_PRR_SEXV.json\n",
      "series no. 382\n",
      "---Series VC_PRS_UNSEC: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_16.3.2_Series_VC_PRS_UNSEC.json\n",
      "series no. 383\n",
      "---Series VC_SNS_WALN: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_16.1.4_Series_VC_SNS_WALN.json\n",
      "series no. 384\n",
      "---Series VC_VAW_MARR: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_5.2.1_Series_VC_VAW_MARR.json\n",
      "series no. 385\n",
      "---Series VC_VAW_MTUHRA: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_16.10.1_Series_VC_VAW_MTUHRA.json\n",
      "series no. 386\n",
      "---Series VC_VAW_PHYPYV: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_16.2.1_Series_VC_VAW_PHYPYV.json\n",
      "series no. 387\n",
      "---Series VC_VAW_SXVLN: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_16.2.3_Series_VC_VAW_SXVLN.json\n",
      "series no. 388\n",
      "---Series VC_VOV_PHYL: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_16.1.3_Series_VC_VOV_PHYL.json\n",
      "series no. 389\n",
      "---Series VC_VOV_ROBB: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_16.1.3_Series_VC_VOV_ROBB.json\n",
      "series no. 390\n",
      "---Series VC_VOV_SEXL: Processing page 1 of 1\n",
      "created file 2019.Q3.G.01\\Indicator_16.1.3_Series_VC_VOV_SEXL.json\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(series)):\n",
    "    if i < 332:\n",
    "        continue\n",
    "    print('series no. ' + str(i))\n",
    "    get_data_to_json(series = series[i], release = release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
